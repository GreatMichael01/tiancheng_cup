{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_train = pd.read_csv(\"../data/operation_train_new.csv\")\n",
    "trans_train = pd.read_csv(\"../data/transaction_train_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "op_test = pd.read_csv(\"../data/operation_round1_new.csv\")\n",
    "trans_test = pd.read_csv(\"../data/transaction_round1_new.csv\")\n",
    "y = pd.read_csv(\"../data/tag_train_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"../data/sub.csv\")\n",
    "def get_feature(op,trans,label):\n",
    "    for feature in op.columns[2:]:\n",
    "        label = label.merge(op.groupby(['UID'])[feature].count().reset_index(),on='UID',how='left')\n",
    "        label =label.merge(op.groupby(['UID'])[feature].nunique().reset_index(),on='UID',how='left')\n",
    "    \n",
    "    for feature in trans.columns[2:]:\n",
    "        if trans_train[feature].dtype == 'object':\n",
    "            label =label.merge(trans.groupby(['UID'])[feature].count().reset_index(),on='UID',how='left')\n",
    "            label =label.merge(trans.groupby(['UID'])[feature].nunique().reset_index(),on='UID',how='left')\n",
    "        else:\n",
    "            label =label.merge(trans.groupby(['UID'])[feature].count().reset_index(),on='UID',how='left')\n",
    "            label =label.merge(trans.groupby(['UID'])[feature].nunique().reset_index(),on='UID',how='left')\n",
    "            label =label.merge(trans.groupby(['UID'])[feature].max().reset_index(),on='UID',how='left')\n",
    "            label =label.merge(trans.groupby(['UID'])[feature].min().reset_index(),on='UID',how='left')\n",
    "            label =label.merge(trans.groupby(['UID'])[feature].sum().reset_index(),on='UID',how='left')\n",
    "            label =label.merge(trans.groupby(['UID'])[feature].mean().reset_index(),on='UID',how='left')\n",
    "            label =label.merge(trans.groupby(['UID'])[feature].median().reset_index(),on='UID',how='left')\n",
    "            label =label.merge(trans.groupby(['UID'])[feature].std().reset_index(),on='UID',how='left')\n",
    "            label =label.merge(trans.groupby(['UID'])[feature].skew().reset_index(),on='UID',how='left')\n",
    "            \n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_feature(op_train,trans_train,y).fillna(-1)\n",
    "test = get_feature(op_test,trans_test,sub).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop([\"UID\", \"Tag\"], axis=1).fillna(value=-1)\n",
    "label = y[\"Tag\"]\n",
    "test_id = test[\"UID\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop([\"UID\", \"Tag\"], axis=1).fillna(value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMClassifier(boosting_type='gbdt',\n",
    "                               num_leaves=64, \n",
    "                               reg_alpha=0,\n",
    "                               reg_lambda=0, \n",
    "                               max_depth=-1,\n",
    "                               n_estimators=1000, \n",
    "                               objective='binary', \n",
    "                               subsample=0.9, \n",
    "                               colsample_bytree=0.8, \n",
    "                               subsample_freq=1, \n",
    "                               learning_rate=0.05,\n",
    "                               random_state=1024,\n",
    "                               n_jobs=6,\n",
    "                               min_child_weight=4, \n",
    "                               min_child_samples=5,\n",
    "                               min_split_gain=0,\n",
    "                               silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.120584\tvalid_1's binary_logloss: 0.139646\n",
      "[100]\tvalid_0's binary_logloss: 0.0827471\tvalid_1's binary_logloss: 0.119957\n",
      "[150]\tvalid_0's binary_logloss: 0.0628112\tvalid_1's binary_logloss: 0.115597\n",
      "[200]\tvalid_0's binary_logloss: 0.049279\tvalid_1's binary_logloss: 0.114954\n",
      "[250]\tvalid_0's binary_logloss: 0.0392405\tvalid_1's binary_logloss: 0.115538\n",
      "[300]\tvalid_0's binary_logloss: 0.0315262\tvalid_1's binary_logloss: 0.11692\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's binary_logloss: 0.0469464\tvalid_1's binary_logloss: 0.114748\n",
      "[0.11474838209897542]\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.120963\tvalid_1's binary_logloss: 0.13472\n",
      "[100]\tvalid_0's binary_logloss: 0.0824262\tvalid_1's binary_logloss: 0.117429\n",
      "[150]\tvalid_0's binary_logloss: 0.062294\tvalid_1's binary_logloss: 0.115531\n",
      "[200]\tvalid_0's binary_logloss: 0.0483557\tvalid_1's binary_logloss: 0.115396\n",
      "[250]\tvalid_0's binary_logloss: 0.0383901\tvalid_1's binary_logloss: 0.115456\n",
      "Early stopping, best iteration is:\n",
      "[190]\tvalid_0's binary_logloss: 0.0508508\tvalid_1's binary_logloss: 0.115153\n",
      "[0.11474838209897542, 0.11515333767402872]\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.117716\tvalid_1's binary_logloss: 0.14654\n",
      "[100]\tvalid_0's binary_logloss: 0.079582\tvalid_1's binary_logloss: 0.129703\n",
      "[150]\tvalid_0's binary_logloss: 0.0600953\tvalid_1's binary_logloss: 0.126918\n",
      "[200]\tvalid_0's binary_logloss: 0.0468182\tvalid_1's binary_logloss: 0.126772\n",
      "[250]\tvalid_0's binary_logloss: 0.0370252\tvalid_1's binary_logloss: 0.128005\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's binary_logloss: 0.0495893\tvalid_1's binary_logloss: 0.12643\n",
      "[0.11474838209897542, 0.11515333767402872, 0.12643011436735888]\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.119191\tvalid_1's binary_logloss: 0.145053\n",
      "[100]\tvalid_0's binary_logloss: 0.0808372\tvalid_1's binary_logloss: 0.12695\n",
      "[150]\tvalid_0's binary_logloss: 0.06107\tvalid_1's binary_logloss: 0.123463\n",
      "[200]\tvalid_0's binary_logloss: 0.047254\tvalid_1's binary_logloss: 0.122449\n",
      "[250]\tvalid_0's binary_logloss: 0.0374368\tvalid_1's binary_logloss: 0.123775\n",
      "[300]\tvalid_0's binary_logloss: 0.0301003\tvalid_1's binary_logloss: 0.125278\n",
      "Early stopping, best iteration is:\n",
      "[201]\tvalid_0's binary_logloss: 0.0470389\tvalid_1's binary_logloss: 0.122412\n",
      "[0.11474838209897542, 0.11515333767402872, 0.12643011436735888, 0.12241217027721028]\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.11895\tvalid_1's binary_logloss: 0.144138\n",
      "[100]\tvalid_0's binary_logloss: 0.0813466\tvalid_1's binary_logloss: 0.125715\n",
      "[150]\tvalid_0's binary_logloss: 0.0613008\tvalid_1's binary_logloss: 0.122756\n",
      "[200]\tvalid_0's binary_logloss: 0.0475511\tvalid_1's binary_logloss: 0.123226\n",
      "[250]\tvalid_0's binary_logloss: 0.0378488\tvalid_1's binary_logloss: 0.124163\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's binary_logloss: 0.0575957\tvalid_1's binary_logloss: 0.122421\n",
      "[0.11474838209897542, 0.11515333767402872, 0.12643011436735888, 0.12241217027721028, 0.1224212725388993]\n"
     ]
    }
   ],
   "source": [
    "oof_preds = np.zeros(train.shape[0])\n",
    "sub_preds = np.zeros(test_id.shape[0])\n",
    "\n",
    "best_score = []\n",
    "skf = StratifiedKFold(n_splits=5, random_state=2018, shuffle=True)\n",
    "for index, (train_index, test_index) in enumerate(skf.split(train, label)):\n",
    "    lgb_model.fit(train.iloc[train_index], label.iloc[train_index], verbose=50,\n",
    "                  eval_set=[(train.iloc[train_index], label.iloc[train_index]),\n",
    "                            (train.iloc[test_index], label.iloc[test_index])], early_stopping_rounds=100)\n",
    "    best_score.append(lgb_model.best_score_['valid_1']['binary_logloss'])\n",
    "    print(best_score)\n",
    "    oof_preds[test_index] = lgb_model.predict_proba(train.iloc[test_index], num_iteration=lgb_model.best_iteration_)[:,1]\n",
    "\n",
    "    test_pred = lgb_model.predict_proba(test, num_iteration=lgb_model.best_iteration_)[:, 1]\n",
    "    sub_preds += test_pred / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['Tag'] = sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"../submission/lgb_baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31198, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.031538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.058121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     UID       Tag\n",
       "0  30000  0.031538\n",
       "1  30001  0.058121"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking\n",
    "sub6173 = pd.read_csv(\"../submission/0.6173.csv\")\n",
    "lgb_bsl = pd.read_csv(\"../submission/lgb_baseline.csv\")\n",
    "UID = sub6173[\"UID\"]\n",
    "prob = 0.5*sub6173[\"Tag\"] + 0.5*lgb_bsl[\"Tag\"]\n",
    "result = pd.DataFrame({\"UID\":UID, \"Tag\": prob})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"../submission/stacking.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
