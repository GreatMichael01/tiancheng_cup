{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/\"\n",
    "operation_train = pd.read_csv(data_dir+\"operation_train_new.csv\")\n",
    "transaction_train = pd.read_csv(data_dir+\"transaction_train_new.csv\")\n",
    "tag_train = pd.read_csv(data_dir+\"tag_train_new.csv\")\n",
    "operation_round1 = pd.read_csv(data_dir+\"operation_round1_new.csv\")\n",
    "transaction_round1 = pd.read_csv(data_dir+\"transaction_round1_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(operation_train[\"UID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transaction_train[\"UID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_round1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_round1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(operation_train[\"UID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_train.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transaction_train[\"UID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_tag_train = pd.merge(operation_train, tag_train, how=\"left\", on=\"UID\")\n",
    "operation_tag_train.to_csv(data_dir + \"operation_tag_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of operation tag:{}\".format(len(operation_tag_train)))\n",
    "operation_tag_train.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_tag_train = pd.merge(transaction_train, tag_train, how=\"left\", on=\"UID\")\n",
    "transaction_tag_train.to_csv(data_dir+\"transaction_tag_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of transaction tag:{}\".format(len(transaction_tag_train)))\n",
    "transaction_tag_train.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_transaction_tag = pd.merge(operation_tag_train, transaction_tag_train, how=\"left\", on=\"UID\")\n",
    "operation_transaction_tag.to_csv(data_dir+\"operation_transaction_tag_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_operation_train = operation_train.shape[0]\n",
    "n_operaton_round1 = operation_round1.shape[0]\n",
    "operation_data = pd.concat([operation_train, operation_round1]).reset_index(drop=True)\n",
    "operation_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_data_na = (operation_data.isnull().sum()/len(operation_data))*100\n",
    "operation_data_na = operation_data_na.drop(operation_data_na[operation_data_na == 0].index).sort_values(ascending=True)\n",
    "missing_operation_data = pd.DataFrame({\"missing ratio\": operation_data_na})\n",
    "print(\"The number of missing item: {}\".format(len(missing_operation_data)))\n",
    "missing_operation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_data[\"success\"] = operation_data[\"success\"].fillna(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### device1 device2 device_code1 device_code2 device_code3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_device = pd.DataFrame()\n",
    "device = operation_data.groupby([\"UID\"]).count()[\"device2\"]\n",
    "uid_device[\"UID\"] = device.index\n",
    "uid_device[\"device\"] = device.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_data.drop([\"device1\", \"device2\", \"device_code1\", \"device_code2\", \"device_code3\"], axis=1, inplace=True)\n",
    "operation_data = pd.merge(operation_data, uid_device, how=\"left\", on=\"UID\")\n",
    "operation_data[\"device\"] = operation_data[\"device\"].fillna(0)\n",
    "mean = operation_data[\"device\"].mean()\n",
    "std = operation_data[\"device\"].std()\n",
    "operation_data[\"device\"] = (operation_data[\"device\"]-mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_data.drop([\"version\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ip1 ip1_sub1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_ip1 = pd.DataFrame()\n",
    "ip1 = operation_data.groupby([\"UID\"]).count()[\"ip1_sub\"]\n",
    "uid_ip1[\"UID\"] = ip1.index\n",
    "uid_ip1[\"ip1\"] = ip1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_data.drop([\"ip1_sub\", \"ip1\"], axis=1, inplace=True)\n",
    "operation_data = pd.merge(operation_data, uid_ip1, how=\"left\", on=\"UID\")\n",
    "operation_data[\"ip1\"] = operation_data[\"ip1\"].fillna(0)\n",
    "mean = operation_data[\"ip1\"].mean()\n",
    "std = operation_data[\"ip1\"].std()\n",
    "operation_data[\"ip1\"] = (operation_data[\"ip1\"]-mean)/std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ip2 ip2_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_ip2 = pd.DataFrame()\n",
    "ip2 = operation_data.groupby([\"UID\"]).count()[\"ip2_sub\"]\n",
    "uid_ip2[\"UID\"] = ip2.index\n",
    "uid_ip2[\"ip2\"] = ip2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_data.drop([\"ip2_sub\", \"ip2\"], axis=1, inplace=True)\n",
    "operation_data = pd.merge(operation_data, uid_ip2, how=\"left\", on=\"UID\")\n",
    "operation_data[\"ip2\"] = operation_data[\"ip2\"].fillna(0)\n",
    "mean = operation_data[\"ip2\"].mean()\n",
    "std = operation_data[\"ip2\"].std()\n",
    "operation_data[\"ip2\"] = (operation_data[\"ip2\"]-mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### geo_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_geo = pd.DataFrame()\n",
    "geo = operation_data.groupby([\"UID\"]).count()[\"geo_code\"]\n",
    "uid_geo[\"UID\"] = geo.index\n",
    "uid_geo[\"geo_code\"] = geo.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_data.drop(\"geo_code\", axis=1, inplace=True)\n",
    "operation_data = pd.merge(operation_data, uid_geo, how=\"left\", on=\"UID\")\n",
    "operation_data[\"geo_code\"] = operation_data[\"geo_code\"].fillna(0)\n",
    "mean = operation_data[\"geo_code\"].mean()\n",
    "std = operation_data[\"geo_code\"].std()\n",
    "operation_data[\"geo_code\"] = (operation_data[\"geo_code\"] - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mac1 mac2 wifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_data.drop([\"mac1\", \"mac2\", \"wifi\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_data_na = (operation_data.isnull().sum()/len(operation_data)) * 100\n",
    "operation_data_na = operation_data_na.drop(operation_data_na[operation_data_na == 0].index).sort_values(ascending = True)\n",
    "missing_operation_data = pd.DataFrame({\"missing ratio\": operation_data_na})\n",
    "print(\"The number of missing item: {}\".format(len(missing_operation_data)))\n",
    "missing_operation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_transaction_train = transaction_train.shape[0]\n",
    "n_transaction_round1 = transaction_round1.shape[0]\n",
    "transaction_data = pd.concat((transaction_train, transaction_round1)).reset_index(drop=True)\n",
    "transaction_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_data_na = (transaction_data.isnull().sum()/len(transaction_data)) * 100\n",
    "transaction_data_na = transaction_data_na.drop(transaction_data_na[transaction_data_na == 0].index).sort_values(ascending = True)\n",
    "missing_transaction_data = pd.DataFrame({\"missing ratio\": transaction_data_na})\n",
    "print(\"the number of missing item: {}\".format(len(missing_transaction_data)))\n",
    "missing_transaction_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trans_type2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_data[\"trans_type2\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_data[\"trans_type2\"] = transaction_data[\"trans_type2\"].fillna(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ip1_sub ip1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transaction_data[\"ip1_sub\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transaction_data[\"ip1\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_ip = pd.DataFrame()\n",
    "ip = transaction_data.groupby([\"UID\"]).count()[\"ip1_sub\"]\n",
    "uid_ip[\"UID\"] = ip.index\n",
    "uid_ip[\"ip\"] = ip.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_data.drop([\"ip1_sub\", \"ip1\"], axis=1, inplace=True)\n",
    "transaction_data = pd.merge(transaction_data, uid_ip, how=\"left\", on=\"UID\")\n",
    "transaction_data[\"ip\"] = transaction_data[\"ip\"].fillna(0)\n",
    "mean = transaction_data[\"ip\"].mean()\n",
    "std = transaction_data[\"ip\"].std()\n",
    "transaction_data[\"ip\"] = (transaction_data[\"ip\"]-mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### device1 device2 device_code1 device_code2 device_code3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_device = pd.DataFrame()\n",
    "device = transaction_data.groupby([\"UID\"]).count()[\"device2\"]\n",
    "uid_device[\"UID\"] = device.index\n",
    "uid_device[\"device\"] = device.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_data.drop([\"device1\", \"device2\", \"device_code1\", \"device_code2\", \"device_code3\"], axis=1, inplace=True)\n",
    "transaction_data = pd.merge(transaction_data, uid_device, how=\"left\", on=\"UID\")\n",
    "transaction_data[\"device\"] = transaction_data[\"device\"].fillna(0)\n",
    "mean = transaction_data[\"device\"].mean()\n",
    "std = transaction_data[\"device\"].std()\n",
    "transaction_data[\"device\"] = (transaction_data[\"device\"]-mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### geo_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_geo = pd.DataFrame()\n",
    "geo = transaction_data.groupby([\"UID\"]).count()[\"geo_code\"]\n",
    "uid_geo[\"UID\"] = geo.index\n",
    "uid_geo[\"geo_code\"] = geo.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_data.drop([\"geo_code\"], axis=1, inplace=True)\n",
    "transaction_data = pd.merge(transaction_data, uid_geo, how=\"left\", on=\"UID\")\n",
    "transaction_data[\"geo_code\"] = transaction_data[\"geo_code\"].fillna(0)\n",
    "mean = transaction_data[\"geo_code\"].mean()\n",
    "std = transaction_data[\"geo_code\"].std()\n",
    "transaction_data[\"geo_code\"] = (transaction_data[\"geo_code\"]-mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### amt_src2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_amt_src = pd.DataFrame()\n",
    "amt_src2 = transaction_data.groupby(\"UID\").count()[\"amt_src2\"]\n",
    "uid_amt_src[\"UID\"] = amt_src2.index\n",
    "uid_amt_src[\"amt_src2\"] = amt_src2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_data.drop(\"amt_src2\", axis=1, inplace=True)\n",
    "transaction_data = pd.merge(transaction_data, uid_amt_src, how=\"left\", on=\"UID\")\n",
    "transaction_data[\"amt_src2\"] = transaction_data[\"amt_src2\"].fillna(0)\n",
    "mean = transaction_data[\"amt_src2\"].mean()\n",
    "std = transaction_data[\"amt_src2\"].std()\n",
    "transaction_data[\"amt_src2\"] = (transaction_data[\"amt_src2\"] - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### market_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_data[\"market_type\"] = transaction_data[\"market_type\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_data.drop(\"market_code\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_data.drop([\"mac1\", \"acc_id1\", \"acc_id2\", \"acc_id3\", \"code1\", \"code2\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_data.drop(\"merchant\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_data_na = (transaction_data.isnull().sum()/len(transaction_data)) * 100\n",
    "transaction_data_na = transaction_data_na.drop(transaction_data_na[transaction_data_na == 0].index).sort_values(ascending = True)\n",
    "missing_transaction_data = pd.DataFrame({\"missing ratio\": transaction_data_na})\n",
    "print(\"The number of missing item: {}\".format(len(missing_transaction_data)))\n",
    "missing_transaction_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_data.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_data['time'] = pd.to_datetime(operation_data['time'])\n",
    "operation_data['time'] = operation_data['time'].apply(lambda x:(x-datetime.now()).seconds/3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = operation_data['time'].mean()\n",
    "std = operation_data['time'].std()\n",
    "operation_data['time'] = (operation_data['time'] - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_data['day'] = operation_data['day'].apply(str)\n",
    "operation_data['mode'] = operation_data['mode'].apply(str)\n",
    "operation_data['success'] = operation_data['success'].apply(str)\n",
    "operation_data['os'] = operation_data['os'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['day', 'mode', 'success', 'os']\n",
    "for col in cols:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(operation_data[col].values))\n",
    "    operation_data[col]=le.transform(list(operation_data[col].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_data.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_data['time'] = pd.to_datetime(transaction_data['time'])\n",
    "transaction_data['time'] = transaction_data['time'].apply(lambda x:(x-datetime.now()).seconds/3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['time', 'trans_amt', 'bal']\n",
    "for col in cols:\n",
    "    mean = transaction_data[col].mean()\n",
    "    std = transaction_data[col].std()\n",
    "    transaction_data[col] = (transaction_data[col] - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['channel', 'day', 'amt_src1', 'trans_type1', 'trans_type2', 'market_type']\n",
    "for col in cols:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(transaction_data[col].values))\n",
    "    transaction_data[col] = le.transform(list(transaction_data[col].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['day', 'mode', 'success', 'os']\n",
    "for col in cols:\n",
    "    operation_data[col] = operation_data[col].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_data = pd.get_dummies(operation_data)\n",
    "operation_train = operation_data[:n_operation_train]\n",
    "operation_round1 = operation_data[n_operation_train:]\n",
    "operation_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['channel', 'day', 'amt_src1', 'trans_type1', 'trans_type2', 'market_type']\n",
    "for col in cols:\n",
    "    transaction_data[col] = transaction_data[col].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_data = pd.get_dummies(transaction_data)\n",
    "transaction_train = transaction_data[:n_transaction_train]\n",
    "transaction_round1 = transaction_data[n_transaction_train:]\n",
    "transaction_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_tag_train = pd.merge(operation_train, tag_train, how='left', left_on='UID',right_on='UID')\n",
    "operation_tag_train.to_csv(data_dir + 'operation_tag_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_tag_train = pd.merge(transaction_train, tag_train, how='left', left_on='UID',right_on='UID')\n",
    "transaction_tag_train.to_csv(data_dir + 'transaction_tag_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_round1.to_csv(data_dir+\"operation_round1.csv\", index=False)\n",
    "transaction_round1.to_csv(data_dir+\"transaction_round1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_round1.to_csv(data_dir+\"operation_round1.csv\", index=False)\n",
    "transaction_round1.to_csv(data_dir+\"transaction_round1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "operation_tag_train = pd.read_csv(\"../data/operation_tag_train.csv\")\n",
    "transaction_tag_train = pd.read_csv(\"../data/transaction_tag_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_round1 = pd.read_csv(\"../data/operation_round1.csv\")\n",
    "transaction_round1 = pd.read_csv(\"../data/transaction_round1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_tag_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_tag = operation_tag_train[\"Tag\"]\n",
    "operation_train = operation_tag_train.drop([\"UID\", \"Tag\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_tag = transaction_tag_train[\"Tag\"]\n",
    "transaction_train = transaction_tag_train.drop([\"UID\", \"Tag\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "model1 = cb.CatBoostClassifier(iterations=2000,\n",
    "                               learning_rate=0.05,\n",
    "                               depth=3, \n",
    "                               l2_leaf_reg=4,\n",
    "                               border_count=15,\n",
    "                               loss_function=\"Logloss\",\n",
    "                               verbose=200)\n",
    "cv_m1 = model1.fit(operation_train, operation_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = cb.CatBoostClassifier(iterations=2000,\n",
    "                               learning_rate=0.05,\n",
    "                               depth=3,\n",
    "                               l2_leaf_reg=4,\n",
    "                               border_count=15,\n",
    "                               loss_function=\"Logloss\",\n",
    "                               verbose=200)\n",
    "cv_m2 = model2.fit(transaction_train, transaction_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"../data/sub.csv\")\n",
    "submission.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = submission[\"UID\"].to_frame()\n",
    "uid_operation = pd.merge(uid, operation_round1, how=\"left\", on=[\"UID\"])\n",
    "uid_transaction = pd.merge(uid, transaction_round1, how=\"left\", on=[\"UID\"])\n",
    "operation_uid = uid_operation[\"UID\"]\n",
    "uid_operation.drop([\"UID\"], axis=1, inplace=True)\n",
    "transaction_uid = uid_transaction[\"UID\"]\n",
    "uid_transaction.drop([\"UID\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_pred = model1.predict_proba(uid_operation)\n",
    "transaction_pred = model2.predict_proba(uid_transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_sub = pd.DataFrame()\n",
    "operation_sub[\"UID\"] = operation_uid\n",
    "operation_sub[\"Tag\"] = operation_pred[:, 1]\n",
    "operation_sub.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_sub = pd.DataFrame()\n",
    "transaction_sub[\"UID\"] = transaction_uid\n",
    "transaction_sub[\"Tag\"] = transaction_pred[:, 1]\n",
    "transaction_sub.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_sub = operation_sub.groupby(\"UID\").mean()[\"Tag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_sub = transaction_sub.groupby(\"UID\").mean()[\"Tag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del operation_tag_train\n",
    "del transaction_tag_train\n",
    "\n",
    "del operation_round1\n",
    "del transaction_round1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ensemble = (operation_sub + transaction_sub)/2.0\n",
    "ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission[\"UID\"] = ensemble.index\n",
    "submission[\"Tag\"] = ensemble.values\n",
    "submission.to_csv(\"../data/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xbg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "operation_tag_train = pd.read_csv(\"../data/operation_tag_train.csv\")\n",
    "transaction_tag_train = pd.read_csv(\"../data/transaction_tag_train.csv\")\n",
    "\n",
    "operation_round1 = pd.read_csv(\"../data/operation_round1.csv\")\n",
    "transaction_round1 = pd.read_csv(\"../data/transaction_round1.csv\")\n",
    "\n",
    "operation_tag = operation_tag_train[\"Tag\"]\n",
    "operation_train = operation_tag_train.drop([\"UID\", \"Tag\"], axis=1)\n",
    "\n",
    "transaction_tag = transaction_tag_train[\"Tag\"]\n",
    "transaction_train = transaction_tag_train.drop([\"UID\", \"Tag\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"../data/sub.csv\")\n",
    "\n",
    "uid = submission[\"UID\"].to_frame()\n",
    "uid_operation = pd.merge(uid, operation_round1, how=\"left\", on=[\"UID\"])\n",
    "uid_transaction = pd.merge(uid, transaction_round1, how=\"left\", on=[\"UID\"])\n",
    "operation_uid = uid_operation[\"UID\"]\n",
    "uid_operation.drop([\"UID\"], axis=1, inplace=True)\n",
    "\n",
    "transaction_uid = uid_transaction[\"UID\"]\n",
    "uid_transaction.drop([\"UID\"], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "params = {\"booster\": \"gbtree\",\n",
    "          \"objective\" : \"binary:logistic\",\n",
    "          \"eval_metric\" : \"auc\",\n",
    "          \"verbose\" : 1,\n",
    "          \"eta\" : 0.01,\n",
    "          \"max_delta_step\" : 5,\n",
    "          \"max_depth\" : 20,\n",
    "          \"alpha\" : 10,\n",
    "          \"lambda\" : 10,\n",
    "          \"gamma\" : 2,\n",
    "          \"subsample\" : 0.8,\n",
    "          \"colsample_bylevel\" : 0.8,\n",
    "          \"min_child_weight\" : 5,\n",
    "          \"scale_pos_weight\" : 0.8,\n",
    "          \"n_jobs\" : -1}\n",
    "\n",
    "\n",
    "test_UID = operation_uid\n",
    "test_X = uid_operation\n",
    "train_matrix = xgb.DMatrix(operation_train, operation_tag)\n",
    "test_matrix = xgb.DMatrix(test_X)\n",
    "\n",
    "model1 = xgb.train(params, train_matrix, num_boost_round=3000)\n",
    "operation_pred = model1.predict(test_matrix)\n",
    "\n",
    "operation_sub = pd.DataFrame({\"UID\": test_UID, \"Tag\": operation_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"booster\": \"gbtree\",\n",
    "          \"objective\" : \"binary:logistic\",\n",
    "          \"eval_metric\" : \"auc\",\n",
    "          \"verbose\" : 1,\n",
    "          \"eta\" : 0.01,\n",
    "          \"max_delta_step\" : 5,\n",
    "          \"max_depth\" : 20,\n",
    "          \"alpha\" : 10,\n",
    "          \"lambda\" : 10,\n",
    "          \"gamma\" : 2,\n",
    "          \"subsample\" : 0.8,\n",
    "          \"colsample_bylevel\" : 0.8,\n",
    "          \"min_child_weight\" : 5,\n",
    "          \"scale_pos_weight\" : 0.8,\n",
    "          \"n_jobs\" : -1}\n",
    "\n",
    "\n",
    "test_UID = transaction_uid\n",
    "test_X = uid_transaction\n",
    "train_matrix = xgb.DMatrix(transaction_train, transaction_tag)\n",
    "test_matrix = xgb.DMatrix(test_X)\n",
    "\n",
    "model2 = xgb.train(params, train_matrix, num_boost_round=3000)\n",
    "transaction_pred = model2.predict(test_matrix)\n",
    "\n",
    "transaction_sub = pd.DataFrame({\"UID\": test_UID, \"Tag\": transaction_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_sub = operation_sub.groupby(\"UID\").mean()[\"Tag\"]\n",
    "transaction_sub = transaction_sub.groupby(\"UID\").mean()[\"Tag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = (operation_sub + transaction_sub)/2.0\n",
    "submission = pd.DataFrame()\n",
    "submission[\"UID\"] = ensemble.index\n",
    "submission[\"Tag\"] = ensemble.values\n",
    "submission.to_csv(\"../data/submission2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#使用sklearn自带的boston数据集\n",
    "boston_data = datasets.load_boston()\n",
    "df_boston = pd.DataFrame(boston_data.data,columns=boston_data.feature_names)\n",
    "df_boston['target'] = pd.Series(boston_data.target)\n",
    "\n",
    "xtrain = df_boston.head(500).drop(['target'],axis=1)\n",
    "ytrain = df_boston.head(500).target\n",
    "\n",
    "xtest = df_boston.tail(6).drop(['target'],axis=1)\n",
    "ytest = df_boston.tail(6).target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:29:05] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[0]\ttrain-rmse:21.7093\ttest-rmse:17.3474\n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 10 rounds.\n",
      "[10:29:05] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[1]\ttrain-rmse:19.6869\ttest-rmse:15.0228\n",
      "[10:29:06] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[2]\ttrain-rmse:17.8982\ttest-rmse:13.2654\n",
      "[10:29:06] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[3]\ttrain-rmse:16.2475\ttest-rmse:11.6048\n",
      "[10:29:06] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[4]\ttrain-rmse:14.7695\ttest-rmse:10.0835\n",
      "[10:29:06] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[5]\ttrain-rmse:13.5417\ttest-rmse:8.49356\n",
      "[10:29:06] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[6]\ttrain-rmse:12.3675\ttest-rmse:7.26111\n",
      "[10:29:06] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[7]\ttrain-rmse:11.3112\ttest-rmse:6.23273\n",
      "[10:29:06] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[8]\ttrain-rmse:10.3767\ttest-rmse:5.15305\n",
      "[10:29:06] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[9]\ttrain-rmse:9.54068\ttest-rmse:4.24451\n",
      "[10:29:06] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[10]\ttrain-rmse:8.80674\ttest-rmse:3.72274\n",
      "[10:29:06] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[11]\ttrain-rmse:8.10549\ttest-rmse:3.28673\n",
      "[10:29:06] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[12]\ttrain-rmse:7.5088\ttest-rmse:3.17986\n",
      "[10:29:06] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[13]\ttrain-rmse:6.98417\ttest-rmse:3.18837\n",
      "[10:29:06] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[14]\ttrain-rmse:6.51555\ttest-rmse:3.28654\n",
      "[10:29:06] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[15]\ttrain-rmse:6.10498\ttest-rmse:3.4315\n",
      "[10:29:06] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[16]\ttrain-rmse:5.74395\ttest-rmse:3.51674\n",
      "[10:29:06] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[17]\ttrain-rmse:5.41198\ttest-rmse:3.65761\n",
      "[10:29:06] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[18]\ttrain-rmse:5.11477\ttest-rmse:3.84013\n",
      "[10:29:06] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[19]\ttrain-rmse:4.86481\ttest-rmse:3.97942\n",
      "[10:29:06] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[20]\ttrain-rmse:4.63408\ttest-rmse:4.15275\n",
      "[10:29:06] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[21]\ttrain-rmse:4.44914\ttest-rmse:4.26283\n",
      "[10:29:06] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[22]\ttrain-rmse:4.27886\ttest-rmse:4.467\n",
      "Stopping. Best iteration:\n",
      "[12]\ttrain-rmse:7.5088\ttest-rmse:3.17986\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'eta':0.1,\n",
    "    'max_depth':2,\n",
    "    'min_child_weight':3,\n",
    "    'gamma':0,\n",
    "    'subsample':.8,\n",
    "    'colsample_bytree':.7,\n",
    "    'reg_alpha':1,\n",
    "    'objective':'reg:linear'\n",
    "}\n",
    "dtrain = xgb.DMatrix(xtrain,ytrain)\n",
    "dtest = xgb.DMatrix(xtest,ytest)\n",
    "watchlist1 = [(dtrain,'train'),(dtest,'test')]\n",
    "\n",
    "model1 = xgb.train(params=params,dtrain=dtrain,num_boost_round=100,early_stopping_rounds=10,evals=watchlist1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = model1.predict(xgb.DMatrix(xtest),ntree_limit=model1.best_iteration)\n",
    "mse1 = mean_squared_error(ytest,result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.802571870358932"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:21.7093\tvalidation_1-rmse:17.3474\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-rmse:19.6869\tvalidation_1-rmse:15.0228\n",
      "[2]\tvalidation_0-rmse:17.8982\tvalidation_1-rmse:13.2654\n",
      "[3]\tvalidation_0-rmse:16.2475\tvalidation_1-rmse:11.6048\n",
      "[4]\tvalidation_0-rmse:14.7695\tvalidation_1-rmse:10.0835\n",
      "[5]\tvalidation_0-rmse:13.5417\tvalidation_1-rmse:8.49356\n",
      "[6]\tvalidation_0-rmse:12.3675\tvalidation_1-rmse:7.26111\n",
      "[7]\tvalidation_0-rmse:11.3112\tvalidation_1-rmse:6.23273\n",
      "[8]\tvalidation_0-rmse:10.3767\tvalidation_1-rmse:5.15305\n",
      "[9]\tvalidation_0-rmse:9.54068\tvalidation_1-rmse:4.24451\n",
      "[10]\tvalidation_0-rmse:8.80674\tvalidation_1-rmse:3.72274\n",
      "[11]\tvalidation_0-rmse:8.10549\tvalidation_1-rmse:3.28673\n",
      "[12]\tvalidation_0-rmse:7.5088\tvalidation_1-rmse:3.17986\n",
      "[13]\tvalidation_0-rmse:6.98417\tvalidation_1-rmse:3.18837\n",
      "[14]\tvalidation_0-rmse:6.51555\tvalidation_1-rmse:3.28654\n",
      "[15]\tvalidation_0-rmse:6.10498\tvalidation_1-rmse:3.4315\n",
      "[16]\tvalidation_0-rmse:5.74395\tvalidation_1-rmse:3.51674\n",
      "[17]\tvalidation_0-rmse:5.41198\tvalidation_1-rmse:3.65761\n",
      "[18]\tvalidation_0-rmse:5.11477\tvalidation_1-rmse:3.84013\n",
      "[19]\tvalidation_0-rmse:4.86481\tvalidation_1-rmse:3.97942\n",
      "[20]\tvalidation_0-rmse:4.63408\tvalidation_1-rmse:4.15275\n",
      "[21]\tvalidation_0-rmse:4.44914\tvalidation_1-rmse:4.26283\n",
      "[22]\tvalidation_0-rmse:4.27886\tvalidation_1-rmse:4.467\n",
      "Stopping. Best iteration:\n",
      "[12]\tvalidation_0-rmse:7.5088\tvalidation_1-rmse:3.17986\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.7, gamma=0, learn_rate=0.1, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=2, min_child_weight=3, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None, objective='reg:linear',\n",
       "       random_state=0, reg_alpha=1, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "model2 = XGBRegressor(\n",
    "    learn_rate = 0.1,\n",
    "    max_depth = 2,\n",
    "    min_child_weight = 3,\n",
    "    gamma = 0,\n",
    "    subsample = 0.8,\n",
    "    colsample_bytree = 0.7,\n",
    "    reg_alpha = 1,\n",
    "    objective = 'reg:linear',\n",
    "    n_estimators = 100\n",
    ")\n",
    "watchlist2 = [(xtrain,ytrain),(xtest,ytest)]\n",
    "model2.fit(xtrain,ytrain,eval_set=watchlist2,early_stopping_rounds=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = model2.predict(xtest,ntree_limit=model2.best_iteration)\n",
    "mse2 = mean_squared_error(ytest,result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.802571870358932"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
